\documentclass[../../main.tex]{subfiles}
\begin{document}
\chapter{Steepest Descent}\label{ch:SD}

Let $A$ be SPD, with a given $\mathbf{x}_0$ and the residual $\mathbf{r}_0 = \mathbf{b} - A\mathbf{x}_0$, then

\begin{align*}
    \mathcal{L}              & = \mathcal{K} = \operatorname{span}\{\mathbf{r}\}                                                                                                              \\
    \mathbf{x}_{k+1}         & = \mathbf{x}_k + \alpha_k \mathbf{r}_k, \quad \alpha_k = \|\mathbf{r}_k\|_2^2 / \mathbf{r}_k^{\top} A \mathbf{r}_k                                             \\
    \mathbf{d}_k             & = \mathbf{x}_{\star} - \mathbf{x}_k                                                                                                                            \\
    \|\mathbf{d}_{k+1}\|_A   & \leq \|\mathbf{d}_k\|_A                                                                                                                                        \\
    \|\mathbf{d}_{k+1}\|_A^2 & = \|\mathbf{d}_k\|_A^2\left(1 - \frac{(\mathbf{r}_k^{\top} \mathbf{r}_k)^2}{\mathbf{r}_k^{\top} A \mathbf{r}_k \mathbf{r}_k^{\top} A^{-1} \mathbf{r}_k}\right)
\end{align*}

Let $B \in \mathbb{R}^{n \times n}$ be SPD, and using Kantorovich's inequality \ref{thm:kantorovich} then for all $\mathbf{x} \in \mathbb{R}^n$
\[
    \frac{\|\mathbf{x}\|_B^2 \|\mathbf{x}\|_{B^{-1}}^2}{\|\mathbf{x}\|_2^4} \leq \frac{1}{4}\cdot\frac{(\lambda_1 + \lambda_n)^2}{\lambda_1 \lambda_n}, \qquad \lambda_1 \geq \ldots \geq \lambda_n > 0
\]

$B$ is SPD so there exists $Q$ orthogonal and $\Lambda = \operatorname{diag}(\lambda_1, \ldots, \lambda_n)$ such that $B = Q^{\top}\Lambda Q$. Choose $\|\mathbf{x}\|_2 = 1$ where $\|Q \mathbf{x}\|_2 = \|\mathbf{x}\|_2 = 1$. Then:
\begin{align*}
    B^{-1}                    & = Q^{\top} \Lambda^{-1} Q                                                                                                           \\
    \|\mathbf{x}\|_B^2        & = \mathbf{x}^{\top} B \mathbf{x} = (Q\mathbf{x})^{\top} \Lambda (Q\mathbf{x}) = \sum_{i=1}^n \lambda_i y_i^2, \quad y = Q\mathbf{x} \\
    \|\mathbf{x}\|_{B^{-1}}^2 & = \mathbf{x}^{\top} B^{-1} \mathbf{x} = (Q\mathbf{x})^{\top} \Lambda^{-1} (Q\mathbf{x}) = \sum_{i=1}^n \lambda_i^{-1} y_i^2         \\
\end{align*}
$(\overline{\lambda}, \overline{\lambda}^{-1})$ as a weighted discre center of gravity for the point $(\lambda_i, \frac{1}{\lambda_i})$ for $i = 1, \ldots, n$.

\[ \ell(\lambda) = \frac{1}{\lambda_1} + \frac{1}{\lambda_n} - \frac{\lambda}{\lambda_1 \lambda_n}, \qquad \ell(\lambda_1) = \frac{1}{\lambda_1}, \qquad \ell(\lambda_n) = \frac{1}{\lambda_n} \]

Then $(\bar\lambda, \bar{\lambda}^{-1})$ is below $\ell(\lambda)$:
\[
    \bar\lambda^{-1} \leq \ell(\bar\lambda)
\]
which has maximum at $\lambda = \tfrac12(\lambda_1 + \lambda_n)$.
\[
    \bar\lambda \bar\lambda^{-1} \leq \frac{(\lambda_1 + \lambda_n)^2}{4 \lambda_1 \lambda_n} = \bar\lambda\left(\frac{1}{\lambda_1} + \frac{1}{\lambda_n}\right)
\]


If $A$ has the eigenvalues $0 < \lambda_1 \leq \ldots \leq \lambda_n$, then:
\begin{align*}
    \frac{\|\mathbf{r}_k\|_2^4}{\|\mathbf{r}_k\|_A^2 \|\mathbf{r}_k\|_{A^{-1}}^2} & \geq \frac{4 \lambda_1 \lambda_n}{(\lambda_1 + \lambda_n)^2}                                      \\
    \|\mathbf{d}_{k+1}\|_A^2                                                      & \leq \|\mathbf{d}_k\|_A^2\left(1 - 4 \frac{\lambda_1 \lambda_n}{(\lambda_1 + \lambda_n)^2}\right) \\
                                                                                  & = \|\mathbf{d}_k\|_A^2\left(\frac{\lambda_n - \lambda_1}{\lambda_n + \lambda_1}\right)^2
\end{align*}

\begin{example}{Discrete Laplacian in 2D}{}
    \begin{align*}
        A & =
        \begin{bmatrix}
            B  & -I &        &        & 0  \\
            -I & B  & -I     &        &    \\
               & -I & \ddots & \ddots &    \\
               &    & \ddots & \ddots & -I \\
            0  &    &        & -I     & B
        \end{bmatrix} \in \mathbb{R}^{N^2 \times N^2},
        \begin{bmatrix}
            4  & -1 &        & 0 \\
            -1 & 4  & -1     &   \\
               & -1 & \ddots &   \\
            0  &    &        & 4
        \end{bmatrix} \in \mathbb{R}^{N \times N} \\
    \end{align*}
    Eigenvalues of $A$:
    \[
        \lambda_{ij} = 4 - 2\left(\cos\left(\frac{i \pi}{N+1}\right) + \cos\left(\frac{j \pi}{N+1}\right)\right), \quad i, j = 1, \ldots, N
    \]
    \begin{align*}
        \lambda_{\max}                                                          & = 4 \text{ if } N \text{ odd}                                                                                                                \\
        \lambda_{\min}                                                          & = 4 - 4\cos\left(\frac{\pi}{N+1}\right)                                                                                                      \\
        \frac{\lambda_{\max} - \lambda_{\min}}{\lambda_{\max} + \lambda_{\min}} & = \frac{4\cos\left(\frac{\pi}{N+1}\right)}{8 - 4\cos\left(\frac{\pi}{N+1}\right)} \approx 1 - \frac12\left(\frac{\pi}{N+1}\right)^2 + \ldots \\
    \end{align*}
    So for $N$ large, convergence is slow.
\end{example}

\section*{Other 1D projection methods}
Let $\mathcal{K} = \operatorname{span}\{\mathbf{v}\}$, $\mathcal{L} = \operatorname{span}\{\mathbf{w}\}$.
One step, starting from $\mathbf{x}_0$:
\begin{align*}
    \tilde{\mathbf{x}} & = \mathbf{x}_0 + \alpha \mathbf{v}, \quad \alpha = \frac{\mathbf{w}^{\top} \mathbf{r}_0}{\mathbf{w}^{\top} A \mathbf{v}} \\
    \tilde{\mathbf{r}} & = \mathbf{b} - A\tilde{\mathbf{x}} = \mathbf{r}_0 - \alpha A \mathbf{v}
\end{align*}
if SD: $\mathbf{v} = \mathbf{w} = \mathbf{r}_0$.


\begin{example}{}{}
    If $A$ is SPD, with $\mathcal{L} = \mathcal{K} = \operatorname{span}\{\mathbf{r}_k\}$, then:
    \begin{align*}
        \mathbf{x}_{k+1} & = \mathbf{x}_k + \alpha_k \mathbf{r}_k, \quad \alpha_k  \in  \mathbb{R}             \\
        \mathbf{r}_{k+1} & = \mathbf{b} - A \mathbf{x}_{k+1} = \mathbf{r}_k - \alpha_k A \mathbf{r}_k                   \\
        \mathbf{r}_{k+1} & \perp \mathbf{r}_k \Rightarrow \mathbf{r}_k^{\top} (\mathbf{r}_k - \alpha_k A \mathbf{r}_k) = 0 \quad
        \Rightarrow \alpha_k = \frac{\mathbf{r}_k^{\top} \mathbf{r}_k}{\mathbf{r}_k^{\top} A \mathbf{r}_k}              \\
        \mathbf{d}_k     & = \mathbf{x}_\star - \mathbf{x}_k                                                   \\
        \mathbf{r}_k     & = \mathbf{b} - A \mathbf{x}_k = A \mathbf{x}_\star - A \mathbf{x}_k = A \mathbf{d}_k                  \\
    \end{align*}

    We want to estimate $\|d_{k+1}\|_A \leq C \|d_k\|_A$ for some $C < 1$.
    \begin{align*}
        \mathbf{r}_{k+1}         & = \mathbf{b} - A \mathbf{x}_{k+1} = A(\mathbf{x}_\star - \mathbf{x}_{k+1}) = A \mathbf{d}_{k+1} = A \mathbf{d}_k - \alpha_k A \mathbf{r}_k \\
        \mathbf{d}_{k+1}         & = \mathbf{d}_{k+1}^{\top} A \mathbf{d}_{k+1} = \mathbf{d}_{k+1}^{\top} \mathbf{r}_{k+1}                                 \\
                        & = (\mathbf{d}_k - \alpha_k \mathbf{r}_k)^{\top} \mathbf{r}_{k+1} = \mathbf{d}_k^{\top} \mathbf{r}_{k+1}                          \\
                        & = \mathbf{d}_k^{\top} (\mathbf{r}_k - \alpha_k A \mathbf{r}_k) = \mathbf{d}_k^{\top} \mathbf{r}_k - \alpha_k \mathbf{d}_k^{\top} A \mathbf{r}_k    \\
                        & = \mathbf{d}_k^{\top} A \mathbf{d}_k - \alpha_k \mathbf{r}_k^{\top} \mathbf{r}_k                                        \\
                        & = \|\mathbf{d}_k\|_A^2 - \alpha_k \|\mathbf{r}_k\|^2                                                   \\
                        & = \|\mathbf{d}_k\|_A^2 - \frac{\|\mathbf{r}_k\|^4}{\|\mathbf{r}_k\|_A^2}                                        \\
        \|\mathbf{d}_{k+1}\|_A^2 & = \|\mathbf{d}_k\|_A^2\left(1 - \frac{\|\mathbf{r}_k\|^4}{\|\mathbf{r}_k\|_A^2 \|\mathbf{r}_k\|_{A^{-1}}^2}\right)
    \end{align*}
\end{example}

\end{document}